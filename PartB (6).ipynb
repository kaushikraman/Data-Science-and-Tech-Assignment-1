{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3418cc28-061b-4f40-8a2e-7e4f7d842e71",
   "metadata": {},
   "source": [
    "# Assignment – 1 #\n",
    "## Predictive Modelling of Eating-Out Problem ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560aac12-96c9-4566-94f6-8988883a3ab1",
   "metadata": {},
   "source": [
    "## Part B – Predictive Modelling ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d372dfb5-6c9f-41cf-8104-d3af16efa632",
   "metadata": {},
   "source": [
    "#### Importing all Libraries ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b224239-0682-4109-baf3-b64966caa15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd1e87a-7d53-4e73-809c-4eba73bedf5b",
   "metadata": {},
   "source": [
    "#### Lodaing Data Set ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "736d2c0e-d3b7-4c45-817d-2a8e90d2de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the restaurant data\n",
    "csv_file_path = 'zomato_df_final_data.csv'\n",
    "data = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b563016-ff6b-445c-8b55-2871f4c0dcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (10500, 17)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the dataset:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb5c1ad-4db6-4b31-ac46-39a38f7193e0",
   "metadata": {},
   "source": [
    "### I. Feature Engineering ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8d5332-1a42-4294-95f1-3084187afdc1",
   "metadata": {},
   "source": [
    "#### 1. Checking for Missing Values ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e46367eb-e963-4d37-8210-a11f54e30694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "address             0\n",
      "cost              346\n",
      "cuisine             0\n",
      "lat               192\n",
      "link                0\n",
      "lng               192\n",
      "phone               0\n",
      "rating_number    3316\n",
      "rating_text      3316\n",
      "subzone             0\n",
      "title               0\n",
      "type               48\n",
      "votes            3316\n",
      "groupon             0\n",
      "color               0\n",
      "cost_2            346\n",
      "cuisine_color       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values of the dataset\n",
    "missing_values = data.isna().sum()\n",
    "\n",
    "# Display the number of missing values for each column\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896532e4-2625-46dc-b296-c54ff7b3afc8",
   "metadata": {},
   "source": [
    "#### 1. Imputating Missing Values ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b70e7ed7-9588-469b-97bb-54afbcf55c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For numerical columns fill NaN with the mean\n",
    "for column in data.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    data[column] = data[column].fillna(data[column].median())  \n",
    "\n",
    "# For categorical columns fill NaN with the most common value\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    data[column] = data[column].fillna(data[column].mode()[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62a5af34-998f-48b2-89e7-d56e87c7997a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "address          0\n",
      "cost             0\n",
      "cuisine          0\n",
      "lat              0\n",
      "link             0\n",
      "lng              0\n",
      "phone            0\n",
      "rating_number    0\n",
      "rating_text      0\n",
      "subzone          0\n",
      "title            0\n",
      "type             0\n",
      "votes            0\n",
      "groupon          0\n",
      "color            0\n",
      "cost_2           0\n",
      "cuisine_color    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check again\n",
    "missing_values = data.isna().sum()\n",
    "\n",
    "# Display the number of missing values for each column\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a214214e-02ec-4afe-8992-48768d265ddd",
   "metadata": {},
   "source": [
    "#### 2. lable/Feature Encodding ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42f5f15a-616e-438d-ad7f-970528e84347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string representation of lists to actual lists for cuisine and type\n",
    "data['cuisine'] = data['cuisine'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "data['type'] = data['type'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c38c4d17-81a4-499a-83cc-4a74fe6ecf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# One-Hot Encode cuisine column and rename columns with prefix cuisine_\n",
    "mlb_cuisine = MultiLabelBinarizer()\n",
    "cuisine_encoded = pd.DataFrame(mlb_cuisine.fit_transform(data['cuisine']), \n",
    "                               columns=[f'cuisine_{col}' for col in mlb_cuisine.classes_], \n",
    "                               index=data.index)\n",
    "data = pd.concat([data, cuisine_encoded], axis=1)\n",
    "\n",
    "# One-Hot Encode type column\n",
    "mlb_type = MultiLabelBinarizer()\n",
    "type_encoded = pd.DataFrame(mlb_type.fit_transform(data['type']), \n",
    "                            columns=[f'type_{col}' for col in mlb_type.classes_], \n",
    "                            index=data.index)\n",
    "data = pd.concat([data, type_encoded], axis=1)\n",
    "data = data.drop(columns=[\"cuisine\",\"type\"], errors='ignore')\n",
    "\n",
    "\n",
    "\n",
    "data['groupon'] = data['groupon'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a2c4a9f-8597-48b5-9197-6e106b9d61f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (10500, 163)\n",
      "Index(['address', 'cost', 'lat', 'link', 'lng', 'phone', 'rating_number',\n",
      "       'rating_text', 'subzone', 'title',\n",
      "       ...\n",
      "       'type_Casual Dining', 'type_Club', 'type_Dessert Parlour',\n",
      "       'type_Fast Food', 'type_Fine Dining', 'type_Food Court',\n",
      "       'type_Food Stall', 'type_Food Truck', 'type_Pub', 'type_Wine Bar'],\n",
      "      dtype='object', length=163)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the dataset and columns after encoding\n",
    "print(\"Shape of the dataset:\", data.shape)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce7b89-a86e-4877-a288-a9446efaaf30",
   "metadata": {},
   "source": [
    "### II. Regression ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bf6c7a-7097-4c0e-ae13-60a0c45dea71",
   "metadata": {},
   "source": [
    "#### 3. Leanier Regression Model ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3622901f-4906-4515-94b6-ba864b28b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Drop non-numeric columns that cannot be used in the regression\n",
    "non_numeric_columns = ['address', 'url', 'phone', 'cuisine', 'title', 'subzone', 'type','link','color','cuisine_color',\"cost_2\"]  # Adjust based on your dataset\n",
    "data = data.drop(columns=non_numeric_columns, errors='ignore')\n",
    "data.to_csv('cleaned_encoded_data.csv', index=False)\n",
    "data = data.drop(columns=\"rating_text\", errors='ignore')\n",
    "\n",
    "# Check if there are any other non-numeric columns (excluding target)\n",
    "X = data.drop(columns=['rating_number'])  # Features\n",
    "X = X.select_dtypes(include=['number'])   # Ensure only numeric features are use\n",
    "\n",
    "# Target variable - numeric rating\n",
    "y = data['rating_number']\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# Feature scaling (optional but recommended for linear models)\n",
    "\n",
    "# Build the Linear Regression Model\n",
    "model_regression_1 = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "model_regression_1.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model_regression_1.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) for model evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a234cb73-dee8-47d6-a9a8-bc001a3daa37",
   "metadata": {},
   "source": [
    "#### 4. Gradient Descent ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d101e873-0dce-40f9-900b-4531b3c35447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling \n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build the Linear Regression Model using Gradient Descent with additional parameters\n",
    "model_regression_2 = SGDRegressor(max_iter=5000, tol=1e-4, eta0=0.0001, learning_rate='constant', alpha=0.0001)\n",
    "\n",
    "# Train the model on the training data\n",
    "model_regression_2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_sgd = model_regression_2.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) for model evaluation\n",
    "mse_sgd = mean_squared_error(y_test, y_pred_sgd)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1b0aa4-5c42-4d7d-855a-684525cb08ec",
   "metadata": {},
   "source": [
    "#### 5. Report of the Models ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b45e9ea-b778-4b7d-a3e9-d5d026433476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                Model Type           Mean Squared Error   Root Mean Squared Error   R-squared \n",
      "------------------------------------------------------------------------------------------\n",
      "model_regression_1   Linear Regression    0.09240              0.30397                   0.28817   \n",
      "model_regression_2   Gradient Descent     0.09236              0.30391                   0.28849   \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) for Linear Regression\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)  # RMSE for Linear Regression\n",
    "r2_linear = r2_score(y_test, y_pred)  # R² for Linear Regression\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) for SGD Regressor\n",
    "mse_sgd = mean_squared_error(y_test, y_pred_sgd)\n",
    "rmse_sgd = np.sqrt(mse_sgd)  # RMSE for SGD\n",
    "r2_sgd = r2_score(y_test, y_pred_sgd)  # R² for SGD Regressor\n",
    "\n",
    "# Print the results in a formatted table\n",
    "print(f\"{'Model':<20} {'Model Type':<20} {'Mean Squared Error':<20} {'Root Mean Squared Error':<25} {'R-squared':<10}\")\n",
    "print(f\"{'-'*90}\")\n",
    "print(f\"{'model_regression_1':<20} {'Linear Regression':<20} {mse:<20.5f} {rmse:<25.5f} {r2_linear:<10.5f}\")\n",
    "print(f\"{'model_regression_2':<20} {'Gradient Descent':<20} {mse_sgd:<20.5f} {rmse_sgd:<25.5f} {r2_sgd:<10.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcb7526-4e1e-4e60-9c72-88848cb2cd0c",
   "metadata": {},
   "source": [
    "Both models performed similarly, with the Gradient Descent model slightly outperforming the Linear Regression model. The R² values around 0.29 indicate that both models explain approximately 29% of the variance in the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ca6d1a-cc33-456c-b4be-03c7750ffe1b",
   "metadata": {},
   "source": [
    "### III. Classification ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fce6a9-e731-43a4-b250-b7306122dab7",
   "metadata": {},
   "source": [
    "#### 6. Classfying Ratings ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c405089-45be-4208-ad07-56ab1bf20f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  rating_text  binary_class\n",
      "0   Very Good             2\n",
      "1   Excellent             2\n",
      "2   Excellent             2\n",
      "3   Excellent             2\n",
      "4   Excellent             2\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = 'cleaned_encoded_data.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "# Function to classify ratings into binary classes\n",
    "def classify_rating(rating):\n",
    "    # Class 1: Poor, Average\n",
    "    if rating in ['Poor', 'Average']:\n",
    "        return 1  \n",
    "    # Class 2: Good, Very Good, Excellent\n",
    "    elif rating in ['Good', 'Very Good', 'Excellent']:\n",
    "        return 2  \n",
    "\n",
    "# Apply the classification to the dataset\n",
    "data['binary_class'] = data['rating_text'].apply(classify_rating)\n",
    "\n",
    "# Verify the classification\n",
    "print(data[['rating_text', 'binary_class']].head())\n",
    "data = data.drop(columns=\"rating_text\", errors='ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c19c618-a07c-4874-8013-00bc5ec8c1a6",
   "metadata": {},
   "source": [
    "#### 7. Logistic regression model ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9130b46d-412f-43c0-bee8-f5fd1b94619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_columns = [col for col in data.columns if col.startswith('cuisine_')]\n",
    "type_columns = [col for col in data.columns if col.startswith('type_')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "18590a02-fba1-4e76-862b-93f3dcdf71f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression model: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Define the features (X) and target (y)\n",
    "features = ['cost','votes'] + cuisine_columns + type_columns\n",
    "X = data[features]\n",
    "y = data['binary_class']  # Target: binary classification\n",
    "\n",
    "# Split the data into training (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Build the logistic regression model\n",
    "model_classification_3 = LogisticRegression(max_iter=5000)\n",
    "\n",
    "# Train the model on the training data\n",
    "model_classification_3.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model_classification_3.predict(X_test)\n",
    "\n",
    "# Evaluate the model using accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy of the model\n",
    "print(f'Accuracy of the Logistic Regression model: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6d3045-2aba-4a55-8f56-389701d4b510",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model Summary\n",
    "\n",
    "- A logistic regression model was implemented to predict a binary classification based on features such as cost, votes, cuisine categories, and type categories.\n",
    "- Data was split into 80% training and 20% test sets.\n",
    "- The model was trained using 5000 iterations to ensure convergence.\n",
    "- The model achieved an accuracy score of 89% on the test data, indicating strong performance in classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804b60d3-288b-4aae-a872-6bcfe6052b8b",
   "metadata": {},
   "source": [
    "#### 8. confusion matrix ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7fef3a19-afe4-4e8e-a954-47b32fcf4c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1584   47]\n",
      " [ 186  283]]\n",
      "\n",
      "Classification Report:\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "            Class 1 (Poor/Average)       0.89      0.97      0.93      1631\n",
      "Class 2 (Good/Very Good/Excellent)       0.86      0.60      0.71       469\n",
      "\n",
      "                          accuracy                           0.89      2100\n",
      "                         macro avg       0.88      0.79      0.82      2100\n",
      "                      weighted avg       0.89      0.89      0.88      2100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model_classification_3.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Optionally, you can also print a classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Class 1 (Poor/Average)', 'Class 2 (Good/Very Good/Excellent)']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1655d816-c2d2-474c-b435-d282a849c275",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "The confusion matrix for the logistic regression model is as follows:\n",
    "\n",
    "- True negatives (Class 1 correctly predicted): 1584\n",
    "- False positives (Class 1 predicted as Class 2): 47\n",
    "- False negatives (Class 2 predicted as Class 1): 186\n",
    "- True positives (Class 2 correctly predicted): 283\n",
    "\n",
    "The model shows a good balance between correctly predicting both classes, with a higher number of correct predictions for Class 1.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7be763-999d-42aa-9560-ed46b838bcb0",
   "metadata": {},
   "source": [
    "#### 10. Extra Models for classification ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1501168-643c-4c81-91f7-f3dc736c910a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Random Forest...\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1525  106]\n",
      " [ 120  349]]\n",
      "\n",
      "Classification Report:\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "            Class 1 (Poor/Average)       0.93      0.94      0.93      1631\n",
      "Class 2 (Good/Very Good/Excellent)       0.77      0.74      0.76       469\n",
      "\n",
      "                          accuracy                           0.89      2100\n",
      "                         macro avg       0.85      0.84      0.84      2100\n",
      "                      weighted avg       0.89      0.89      0.89      2100\n",
      "\n",
      "\n",
      "Evaluating SVM...\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1535   96]\n",
      " [ 112  357]]\n",
      "\n",
      "Classification Report:\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "            Class 1 (Poor/Average)       0.93      0.94      0.94      1631\n",
      "Class 2 (Good/Very Good/Excellent)       0.79      0.76      0.77       469\n",
      "\n",
      "                          accuracy                           0.90      2100\n",
      "                         macro avg       0.86      0.85      0.86      2100\n",
      "                      weighted avg       0.90      0.90      0.90      2100\n",
      "\n",
      "\n",
      "Evaluating Gradient Boosting...\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1522  109]\n",
      " [ 101  368]]\n",
      "\n",
      "Classification Report:\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "            Class 1 (Poor/Average)       0.94      0.93      0.94      1631\n",
      "Class 2 (Good/Very Good/Excellent)       0.77      0.78      0.78       469\n",
      "\n",
      "                          accuracy                           0.90      2100\n",
      "                         macro avg       0.85      0.86      0.86      2100\n",
      "                      weighted avg       0.90      0.90      0.90      2100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a function to train and evaluate models\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Generate the confusion matrix and classification report\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred, target_names=['Class 1 (Poor/Average)', 'Class 2 (Good/Very Good/Excellent)'])\n",
    "    \n",
    "    return conf_matrix, class_report\n",
    "\n",
    "# Models to try\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Iterate over each model and evaluate\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nEvaluating {model_name}...\\n\")\n",
    "    conf_matrix, class_report = evaluate_model(model, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # Print the confusion matrix and classification report for each model\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d77851-21af-454e-acb1-40d1ca9cd3be",
   "metadata": {},
   "source": [
    "### Extra Models for Classification\n",
    "\n",
    "Three additional models were evaluated for binary classification: Random Forest, Support Vector Machine (SVM), and Gradient Boosting. Below are the results for each model:\n",
    "\n",
    "#### 1. Random Forest\n",
    "- **Confusion Matrix**:\n",
    "- **Classification Report**:\n",
    "- Class 1 (Poor/Average): Precision = 0.93, Recall = 0.94, F1-Score = 0.93\n",
    "- Class 2 (Good/Very Good/Excellent): Precision = 0.77, Recall = 0.74, F1-Score = 0.76\n",
    "- **Overall Accuracy**: 89%\n",
    "\n",
    "#### 2. Support Vector Machine (SVM)\n",
    "- **Confusion Matrix**:\n",
    "- **Classification Report**:\n",
    "- Class 1 (Poor/Average): Precision = 0.93, Recall = 0.94, F1-Score = 0.94\n",
    "- Class 2 (Good/Very Good/Excellent): Precision = 0.79, Recall = 0.76, F1-Score = 0.77\n",
    "- **Overall Accuracy**: 90%\n",
    "\n",
    "#### 3. Gradient Boosting\n",
    "- **Confusion Matrix**:\n",
    "- **Classification Report**:\n",
    "- Class 1 (Poor/Average): Precision = 0.94, Recall = 0.93, F1-Score = 0.94\n",
    "- Class 2 (Good/Very Good/Excellent): Precision = 0.77, Recall = 0.78, F1-Score = 0.78\n",
    "- **Overall Accuracy**: 90%\n",
    "\n",
    "In conclusion, the **SVM** and **Gradient Boosting** models provided the highest accuracy at 90%, while **Random Forest** performed slightly lower at 89%.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
